# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

ChemDataExtractor2 is a comprehensive toolkit for extracting chemical information from scientific literature. This is a typed fork under active development with focus on performance optimization, type safety, and real-world application testing.

## Development Environment

**Python Version**: 3.12+ (defaults to Python 3.12.11 via `.python-version`)

### Setup Commands

- Install uv (if not installed): `curl -LsSf https://astral.sh/uv/install.sh | sh`
- Install project with dev dependencies: `uv sync --group dev`
- Run commands in uv environment: `uv run <command>`
- Add new dependencies: `uv add <package>` or `uv add --group dev <package>`

### Testing & Quality Assurance

- Run all tests: `uv run pytest`
- Run specific test: `uv run pytest tests/test_filename.py -v`
- Code formatting: Pre-commit hooks handle ruff formatting automatically
- Type checking: `uv run mypy` (ongoing systematic typing implementation)
- Quality analysis: `uv run ruff check` and `uv run ruff format`

### Git Workflow

- **NEVER push to upstream** (CambridgeMolecularEngineering/ChemDataExtractor2)
- Always push to origin (your fork: chemlynx/ChemDataExtractor2)
- Use feature branches for development
- Current main development branch: `feature/typing-foundation`

## Performance Optimization Work Completed

### Phase 1: Regex Compilation & Caching Optimization âœ… COMPLETED

- **Achievement**: 3.8x â†’ 2.6x performance improvement
- **Implementation**: Created centralized pre-compiled regex pattern registry
- **File**: `chemdataextractor/parse/regex_patterns.py`
- **Impact**: Significant speed improvements across parsing operations

### Phase 2: String Operations Optimization âœ… COMPLETED

- **Achievement**: Fixed critical regex escaping issues
- **Implementation**: Pre-compiled pattern registries with proper escaping
- **Impact**: Resolved 'cliche-ridden' tokenization problems and enhanced performance

### Critical Bug Fixes âœ… COMPLETED

#### ModelList Constructor Issue

- **Problem**: Changed `*models` to `models` during typing work, breaking CEM parsing
- **Solution**: Restored `*models` parameter with proper typing annotations
- **File**: `chemdataextractor/model/base.py`

#### Melting Point Contextual Merging

- **Problem**: MpParser manually extracted fields, losing roles field
- **Solution**: Use contextual merging instead of manual field extraction
- **File**: `chemdataextractor/parse/mp_new.py`

#### Missing Imports for Dynamic Configuration

- **Problem**: Removed imports needed for eval() calls in set_config()
- **Solution**: Restored SentenceTokenizer, WordTokenizer, CrfPosTagger, Lexicon imports
- **File**: `chemdataextractor/doc/text.py`

#### Saccharide Arrow Splitting

- **Problem**: `_is_saccharide_arrow` method couldn't handle nested brackets like `(1â†’4)]-`
- **Solution**: Fixed regex to handle complex chemical nomenclature patterns
- **File**: `chemdataextractor/nlp/tokenize.py`

## Real-World Application Testing

### RSC Publication Analysis âœ… COMPLETED

- **Test Document**: `/tests/data/D5OB00672D.html` (67K characters, 191 elements)
- **Content**: Quinazolinone synthesis and TLX agonist development research
- **Results**: Successfully extracted comprehensive chemical data

### Development and Example Scripts âœ… ORGANIZED

Scripts are now organized in the `scripts/` directory:

- **`scripts/examples/`** - RSC journal article extraction examples
  - `extract_rsc_configurable.py` - User-configurable model selection
  - `extract_rsc_article.py` - Comprehensive extraction with all 11 models
  - `extract_rsc_quick.py` - Fast melting point extraction
  - `extract_rsc_simple.py` - Simple extraction example
  - `rsc_extraction_summary.py` - Capabilities demonstration
  - `main.py` - Basic usage demonstration

- **`scripts/development/`** - Debugging and validation tools
  - `debug_trigger_extraction.py` - Trigger phrase debugging
  - `validate_trigger_optimization.py` - Performance validation
  - `count_mypy_errors.py` - Type checking analysis

- **`scripts/benchmarks/`** - Performance data and analysis results
  - Various JSON files with benchmark results
  - Performance analysis reports

### BERT Model Analysis âœ… COMPLETED

- **Model**: SciBERT (scientific domain pre-trained BERT)
- **Training**: Custom chemical entity recognition data
- **Performance**: ~2-3 minutes initialization time
- **Embeddings**: Chemical-specific embeddings and vocabulary
- **Python Compatibility**: Works with Python 3.9-3.12+ (version agnostic)

## Pending Performance Optimizations

The following optimizations are planned but not yet implemented:

1. **Parser trigger_phrase mechanisms** - 2x speedup potential
2. **Replace pickle with joblib** - Faster model serialization
3. **Lazy loading system** - For large data files
4. **Vectorized NLP operations** - NumPy batch processing
5. **Smart caching for document.records** - Intelligent record caching
6. **Memory optimization** - Reduce parse element creation overhead
7. **Async/await support** - Concurrent document processing
8. **Parser compilation system** - Static rule optimization

## Architecture Overview

### Core Processing Pipeline

1. **Document Loading** - HTML/PDF/XML reader support
2. **Element Extraction** - Paragraphs, tables, figures, headings
3. **NLP Processing** - Tokenization, POS tagging, CEM recognition
4. **Parsing** - Rule-based extraction using grammar patterns
5. **Contextual Merging** - Intelligent linking of compounds and properties
6. **Record Serialization** - JSON output for data integration

### Key Components

- **Document** (`chemdataextractor/doc/`) - Central orchestrator and element hierarchy
- **Readers** (`chemdataextractor/reader/`) - Format-specific document readers
- **NLP** (`chemdataextractor/nlp/`) - Chemistry-aware natural language processing
- **Parsing** (`chemdataextractor/parse/`) - Rule-based extraction engine
- **Models** (`chemdataextractor/model/`) - Data models for chemical information
- **RelEx** (`chemdataextractor/relex/`) - Relationship extraction and pattern learning

### Available Extraction Models

1. **Compound** - Chemical compound identification (requires BERT CRF)
2. **MeltingPoint** - Melting point measurements with compound linking
3. **IrSpectrum** - Infrared spectroscopy data
4. **NmrSpectrum** - Nuclear magnetic resonance data
5. **UvvisSpectrum** - UV-Visible spectroscopy
6. **Apparatus** - Experimental apparatus information
7. **GlassTransition** - Glass transition temperature
8. **ElectrochemicalPotential** - Electrochemical measurements
9. **FluorescenceLifetime** - Fluorescence lifetime data
10. **QuantumYield** - Quantum yield measurements
11. **InteratomicDistance** - Structural distance measurements

## Type Annotation Strategy

### Foundation

- **Core TypeVars**: T, ModelT, ElementT for generic types
- **Key Patterns**: BaseType[T], ModelList[RecordT], Protocol classes
- **Progress**: Systematic addition following phased approach

### Implementation Phases

1. **Phase 1** âœ… - Foundation classes (BaseModel, BaseType, Document)
2. **Phase 2** âœ… - Public APIs and parser framework
3. **Phase 3** âœ… - Internal systems and NLP module
4. **Phase 4** âœ… - Advanced patterns and metaclass typing
5. **Parse Folder Comprehensive Typing** âœ… - All 27 Python files in parse directory
6. **NLP Directory Comprehensive Typing** âœ… - All 16 Python files in nlp directory

### Quality Standards

- Google-style docstrings for all public APIs
- Type annotations required for new code
- MyPy strict mode compliance for core modules
- Include type information in docstring Args/Returns sections

## Development Guidelines

### Code Quality

- **NEVER create files unless absolutely necessary** - Always prefer editing existing files
- **Follow existing patterns** - Mimic code style, use existing libraries
- **Security first** - Never expose secrets, follow security best practices
- **No unnecessary comments** - Code should be self-documenting

### Testing Requirements

- All critical tests must pass before commits
- Validate on real scientific literature when possible
- Performance improvements must be verified and documented
- Test both positive and edge cases

### Git Practices

- Use descriptive commit messages with proper formatting
- Stage and test changes before committing
- Never force push to shared branches

## Current Status

### Completed Work (Ready for Production)

âœ… Phase 1 & 2 performance optimizations (3.8x â†’ 2.6x improvement)
âœ… Critical bug fixes (ModelList, contextual merging, imports, tokenization)
âœ… Real-world RSC publication testing and validation
âœ… Comprehensive extraction script suite
âœ… BERT model analysis and Python compatibility validation
âœ… Comprehensive typing modernization (10,000+ lines across 43+ files)
âœ… Parse directory typing (27 files, 3,700+ lines)
âœ… NLP directory typing (16 files, 8,500+ lines)

### In Progress

ðŸ”„ Documentation and example enhancement

### Next Priorities

ðŸ“‹ Remaining performance optimizations (items 9-16 from original plan)
ðŸ“‹ Production deployment preparation
ðŸ“‹ Extended real-world testing on diverse scientific literature

## Major Typing Modernization Completed

### Parse Directory Comprehensive Typing âœ…

**3,700+ lines across 27 files modernized** with Python 3.12+ type annotations:

- **Phase 1**: Core parsing framework (elements.py, actions.py, common.py, cem.py)
- **Phase 2**: Chemical entity parsing (chemical entity mention parsers)
- **Phase 3**: Domain-specific parsers (nmr.py, ir.py, mp_new.py, tg.py, uvvis.py, apparatus.py)

**Key Achievements**:
- Modern union syntax (`str | None`)
- Generator type annotations for parse methods
- Type aliases for common patterns (TokenList, ParseResult)
- Comprehensive function parameter and return typing
- Enhanced docstrings with Args/Returns sections

### NLP Directory Comprehensive Typing âœ…

**8,500+ lines across 16 files modernized** in 5 systematic phases:

- **Phase 1**: Foundation modules (util.py, lexicon.py, __init__.py)
- **Phase 2**: Core NLP infrastructure (tokenize.py, pos.py, tag.py)
- **Phase 3**: CRF and BERT modules (crf.py, bertcrf_tagger.py, bertcrf_modules.py)
- **Phase 4**: Specialized modules (abbrev.py, subsentence.py, corpus.py)
- **Phase 5**: Dependency parsing modules (dependency.py, corenlp_dependency.py, spacy_dependency.py, new_cem.py)

**Key Achievements**:
- PyTorch tensor typing for neural models
- Iterator and Generator annotations for NLP pipelines
- Complex machine learning model type safety
- Chemistry-aware tokenization and tagging typing
- Dependency parsing with comprehensive type coverage

**Note**: `chemdataextractor/nlp/cem.py` (2,560 lines) was deferred due to size and complexity

### Typing Features Implemented

- `from __future__ import annotations` for Python 3.12+ compatibility
- TYPE_CHECKING guards for forward references
- Modern type syntax throughout all modules
- Comprehensive docstring standardization
- Type aliases for domain-specific patterns
- Generic type parameters where appropriate

## Key Files Modified in Recent Work

### Core Framework (Performance & Bugs)

- `chemdataextractor/parse/regex_patterns.py` - New centralized pattern registry
- `chemdataextractor/model/base.py` - Fixed ModelList constructor
- `chemdataextractor/doc/text.py` - Restored missing imports
- `chemdataextractor/nlp/tokenize.py` - Fixed saccharide arrow splitting
- `chemdataextractor/parse/mp_new.py` - Fixed contextual merging

### Application Scripts

- `extract_rsc_configurable.py` - User-configurable extraction
- `extract_rsc_article.py` - Comprehensive extraction
- `extract_rsc_quick.py` - Fast melting point extraction
- `analyze_rsc_text.py` - Fast text analysis
- `rsc_extraction_summary.py` - Capabilities summary

### Comprehensive Typing Modernization

- **All 27 files** in `chemdataextractor/parse/` - Complete type annotation coverage
- **16 of 17 files** in `chemdataextractor/nlp/` - Modern typing implementation (cem.py deferred)

This represents a significant enhancement to ChemDataExtractor2's performance, reliability, and real-world applicability for scientific literature processing.
